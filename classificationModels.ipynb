{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christopher-c-lee/machine-learning-projects/blob/main/classification-models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MogJ8fSeRrjS"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFqP7oI7RrjT"
      },
      "source": [
        "#### Basic idea for Decision Trees look at one variable at a time.\n",
        "#### So no need to scale the data. \n",
        "#### Also since "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Q08EQA2iRrjU",
        "outputId": "490dded5-8ed4-48fa-fd59-d4c84a67f70c"
      },
      "source": [
        "titanic_unscaled = pd.read_pickle(\"Titanic_PreprocessedData.pkl\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-17805fa20cd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtitanic_unscaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Titanic_PreprocessedData.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;31m# We want to silence any warnings about, e.g. moved modules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m# e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: unsupported pickle protocol: 5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "AIMyTOrDRrjV"
      },
      "source": [
        "titanic_unscaled.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikWwO82VRrjW"
      },
      "source": [
        "#### Now let us divide this into training and validation dataset  - 70% and 30%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EckUivffRrjX"
      },
      "source": [
        "### We are going to use a library called scikit learn (denoted by sklearn) for predictive modeling. It has all the methods we need to build predictive models. \n",
        "\n",
        "\n",
        "###  We split the cleaned up data into training and validation sets. (scikit learn calls them training and test) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0iYmlRSRrjY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "# importing the specific method for randomly splitting the data \n",
        "# Note that this a weird method, it gives 4 dataframes as output ( the specific order is important, the specific names are not) ! \n",
        "## The input to the method is the the set of predictor columns, The single target column, the split rati0\n",
        "# The random_state allows you to create repeatable random splitting. So you get the same split everytime you run it.  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "IHxONmnTRrjZ",
        "outputId": "aa742c71-f9e1-4a42-dfe7-64f64c040454"
      },
      "source": [
        "train_predictors, valid_predictors, train_target, valid_target = train_test_split(titanic_unscaled.drop(columns = {\"survived\"}), \n",
        "                                                    titanic_unscaled[[\"survived\"]], test_size=0.3, random_state=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8681497b1025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_predictors, valid_predictors, train_target, valid_target = train_test_split(titanic_unscaled.drop(columns = {\"survived\"}), \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                     titanic_unscaled[[\"survived\"]], test_size=0.3, random_state=1)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'titanic_unscaled' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV69kMaHRrjZ"
      },
      "source": [
        "train_predictors.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aBOGzVPRrjZ"
      },
      "source": [
        "train_predictors.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQTOwGG7Rrja"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdayCGoeRrja"
      },
      "source": [
        "valid_predictors.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdEx9f4nRrja"
      },
      "source": [
        "train_target.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuMGecTbRrja"
      },
      "source": [
        "valid_target.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7SPkgbXRrjb"
      },
      "source": [
        "valid_target.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "540m8yvgRrjb"
      },
      "source": [
        "### Now we are ready to build a decision tree  model  on the training data \n",
        "### Remember we always build our model only using the training data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRh3MQDmRrjc"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "r2YQhvgNRrjc"
      },
      "source": [
        "tree_titanic = DecisionTreeClassifier(max_depth = 4, min_samples_split=40,min_samples_leaf = 10) # These are parameters that control the tree we build\n",
        "tree_titanic.fit(train_predictors,train_target)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HytOCzLZRrjd"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w9lT69FRrjd"
      },
      "source": [
        "### Now that the model is created, we can apply it to the training and  validation data set to see how accurate its predictons are on the training and validation data set.  Each model type has a .predict method to you which you pass the predictor columns. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYM_sldvRrje"
      },
      "source": [
        "tree_titanic_train_predict = pd.DataFrame(tree_titanic.predict(train_predictors), index = train_target.index, columns = {\"Tree_prediction\"} )\n",
        "tree_titanic_train_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYaJh4HLRrje"
      },
      "source": [
        "tree_titanic_valid_predict = pd.DataFrame(tree_titanic.predict(valid_predictors), index = valid_target.index, columns = {\"Tree_prediction\"} )\n",
        "tree_titanic_valid_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEvJtrNhRrje"
      },
      "source": [
        "## Since we want a dataframe\n",
        "tree_titanic_valid_predict = pd.DataFrame(tree_titanic.predict(valid_predictors), index = valid_target.index, columns = {\"tree_prediction\"} )\n",
        "tree_titanic_valid_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsm9qw98Rrjf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvMmKFOwRrjf"
      },
      "source": [
        "valid_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whx386x0Rrjg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE8R_XfRRrjg"
      },
      "source": [
        "from dmba import classificationSummary # \n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuSVnaNuRrjg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5ocUvTmRrjg"
      },
      "source": [
        "classes = ['Died', 'Survived']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0aqW7Z_Rrjh"
      },
      "source": [
        "print(\"TRAINING CONFUSION MATRIX\")\n",
        "classificationSummary(train_target,tree_titanic_train_predict, class_names=classes) \n",
        "\n",
        "print(\"VALIDATION CONFUSION MATRIX\")\n",
        "\n",
        "classificationSummary(valid_target,tree_titanic_valid_predict, class_names=classes) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDNvgq4NRrjh"
      },
      "source": [
        "valid_target.value_counts() ### checking that the numbers add up ! "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctxQ-l_1Rrji"
      },
      "source": [
        "print(classification_report(valid_target,tree_titanic_valid_predict, target_names=classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irec9R8yRrji"
      },
      "source": [
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pylab as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ypvJciDdRrjj"
      },
      "source": [
        "plt.figure(figsize=(18,12))  # set plot size (denoted in inches)\n",
        "plot_tree(tree_titanic, feature_names=list(train_predictors.columns),filled=True, fontsize=10)\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXXYhqipRrjj"
      },
      "source": [
        "#### Class Exercise: Consider the decision tree above. \n",
        "\n",
        "#### 1.  We just learned about a mystery passenger from some of the survivors who happened to have her ticket - She was a 21 year old  female, who was a 3rd  class passenger, who embarked at Southamption and who had paid a fare of 18 pounds. \n",
        "\n",
        "#### 2. Write down the all prediction rules that results from the above decision tree. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL7iFaoNRrjk"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg3NU2Z0Rrjl"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPS3NxweRrjl"
      },
      "source": [
        "### Now let us fit Random Forests "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8xA5fyURrjl"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYoNXMrsRrjm"
      },
      "source": [
        "#### Now let us fit a random forest model. It is almost exactly the same syntax as for decision trees. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP-ZdCRgRrjm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLqob35-Rrjn"
      },
      "source": [
        "rf_titanic = RandomForestClassifier(n_estimators=20, random_state=1)\n",
        "rf_titanic.fit(train_predictors,train_target)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq41hchGRrjn"
      },
      "source": [
        "rf_titanic_train_predict = pd.DataFrame(rf_titanic.predict(train_predictors), index = train_target.index, columns = {\"rf_prediction\"} )\n",
        "rf_titanic_train_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAViPXITRrjn"
      },
      "source": [
        "rf_titanic_valid_predict = pd.DataFrame(rf_titanic.predict(valid_predictors), index = valid_target.index, columns = {\"rf_prediction\"} )\n",
        "rf_titanic_valid_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dthPXsZSRrjo"
      },
      "source": [
        "#### How good is this random forest model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CRvdx05Rrjo"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oTU5gLkTRrjo"
      },
      "source": [
        "print(\"TRAINING CONFUSION MATRIX\")\n",
        "classificationSummary(train_target,rf_titanic_train_predict, class_names=classes) \n",
        "\n",
        "print(\"VALIDATION CONFUSION MATRIX\")\n",
        "\n",
        "classificationSummary(valid_target,rf_titanic_valid_predict, class_names=classes) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9hbNVC5Rrjp"
      },
      "source": [
        "### Random Forest Models also assign class propensities which are extremely when predicting one class correctly is more important that the other due to the business context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJFGfmUPRrjp"
      },
      "source": [
        "rf_titanic.predict_proba(valid_predictors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao6H1xY1Rrjq"
      },
      "source": [
        "rf_results = pd.DataFrame(rf_titanic.predict_proba(valid_predictors), index = valid_target.index, columns = {\"propensity_for _0\", \"propensity_for_1\"} )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfI_phlORrjq"
      },
      "source": [
        "rf_results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvNnSODtRrjr"
      },
      "source": [
        "rf_results[\"rf_prediction\"] = rf_titanic.predict(valid_predictors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El4TCXRXRrjr"
      },
      "source": [
        "rf_results[\"Actual Class\"] = valid_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WzzOwR5GRrjs"
      },
      "source": [
        "rf_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "D3w_1j9uRrjs"
      },
      "source": [
        "rf_results.rf_prediction.sum() ## confirming the number of predicted ( not actual survivals) from validation dataset "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKucf19CRrjs"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwxCtAkCRrjt"
      },
      "source": [
        "sorted_rf_results = rf_results.sort_values(\"propensity_for_1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ0mmSbQRrjt"
      },
      "source": [
        "sorted_rf_results.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpS2tMqMRrju"
      },
      "source": [
        "sorted_rf_results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgTuPZUeRrju"
      },
      "source": [
        "sorted_rf_results[160:180] ### To see where the prediction changes from 0 to 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb8lZfAIRrjv"
      },
      "source": [
        "forest_importances = pd.DataFrame(rf_titanic.feature_importances_, columns = {\"Importance\"})\n",
        "forest_importances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2xBWheMRrjv"
      },
      "source": [
        "forest_importances[\"Predictor Names\"] =train_predictors.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cUW8qJ4Rrjw"
      },
      "source": [
        "forest_importances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMf0aJFNRrjw"
      },
      "source": [
        "#### The above numbers give you a quantitative measure of the proportional importance of each predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3etdXHkRrjw"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
