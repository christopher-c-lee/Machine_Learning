{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christopher-c-lee/machine-learning-projects/blob/main/ContinuousPrediction_Section_A_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N-980IAV9vK"
      },
      "source": [
        "# Predicting Continuous Targets \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3-IbbtwV9vO"
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3f_u2UdV9vR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "aed9e2ad-ed8f-4482-de94-8db3e26c1a12"
      },
      "source": [
        "car_df = pd.read_csv(\"ToyotaCorollaPrices.csv\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-57e88f6b95f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcar_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ToyotaCorollaPrices.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ToyotaCorollaPrices.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHgdplxrV9vS"
      },
      "source": [
        "car_df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkYwNRQDV9vT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtT_L2WSV9vU"
      },
      "source": [
        "### Just a quick exploration of the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcJ7hTyWV9vU"
      },
      "source": [
        "car_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DUvfxhLV9vV"
      },
      "source": [
        "car_df.Fuel_Type.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOAugAVlV9vW"
      },
      "source": [
        "car_df.Color.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inulLt6iV9vX"
      },
      "source": [
        "car_df.HP.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoHhY-aVV9vX"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSgtvmB7V9vX"
      },
      "source": [
        "car_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "gopk_6cZV9vY"
      },
      "source": [
        "car_df.Color.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thdhPqE0V9vY"
      },
      "source": [
        "sns.displot(x =car_df[\"Price\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzeDlEINV9vZ"
      },
      "source": [
        "sns.boxplot(y =car_df[\"Price\"], x = car_df[\"Fuel_Type\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Hb1MoybcV9vZ"
      },
      "source": [
        "sns.relplot(y =car_df[\"Price\"], x = car_df[\"KM\"], hue = car_df[\"Fuel_Type\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0FiUi7kV9va"
      },
      "source": [
        "sns.relplot(y =car_df[\"Price\"], x = car_df[\"Age\"], hue = car_df[\"Fuel_Type\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xUgah3fV9va"
      },
      "source": [
        "#### Now let us start bulding predcitive models- we will use the following models:\n",
        "    1. Nearest Neighbors\n",
        "    2. Decision Trees \n",
        "    3. Random Forests \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI1C8oDcV9vb"
      },
      "source": [
        "#### First we have to convert categorical variable into numerical - dummy variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD97jB8pV9vb"
      },
      "source": [
        "car_df = pd.get_dummies(car_df, drop_first = True) # more about drop_first next week "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuwzPyOuV9vc"
      },
      "source": [
        "car_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVzJp5IDV9vd"
      },
      "source": [
        "#### Before applying nearest neighbors we have scale the predictor data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbKS00tHV9ve"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler # importing what we need for doing scaling. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIYxkIiDV9ve"
      },
      "source": [
        "ourscaler = MinMaxScaler() # first creating a MinMax scaler object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjoCXGIUV9ve"
      },
      "source": [
        "car_df_scaledPredictors = pd.DataFrame(ourscaler.fit_transform(car_df.drop(columns={\"Price\"})),\n",
        "                               index=car_df.index, columns=car_df.columns.drop(\"Price\")) \n",
        "\n",
        "\n",
        "# we dont need to scale the target "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LLzIT0vV9vf"
      },
      "source": [
        "car_df_scaledPredictors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vj38dQGV9vf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFQ7rn4xV9vf"
      },
      "source": [
        "train_predictors, valid_predictors, train_target, valid_target = train_test_split(car_df_scaledPredictors, \n",
        "                                                    car_df[[\"Price\"]], test_size=0.3, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJWxUhv0V9vg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqiWCoXfV9vg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zhVsrVdAV9vh"
      },
      "source": [
        "train_predictors.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siv2JqCmV9vi"
      },
      "source": [
        " train_target.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnsQ8KCiV9vj"
      },
      "source": [
        "#### Now build Nearest Neighbors Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtoMO1pQV9vj"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFJVMzodV9vk"
      },
      "source": [
        "knnmodel = KNeighborsRegressor(n_neighbors=10) # Creating a knn model object with number neighbors = 5 \n",
        "knnmodel.fit(train_predictors,train_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J73ocw28V9vk"
      },
      "source": [
        "#### Now compute predictions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhdmwfpoV9vk"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwzlCp4VV9vl"
      },
      "source": [
        "knn_valid_predict = pd.DataFrame(knnmodel.predict(valid_predictors), index = valid_target.index, columns = {\"knn_prediction\"}) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvhx-ynZV9vl"
      },
      "source": [
        "knn_valid_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fZuDukR4V9vl"
      },
      "source": [
        "valid_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa_Ka1MZV9vm"
      },
      "source": [
        "!pip install dmba\n",
        "from dmba import regressionSummary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEXP8YlIV9vm"
      },
      "source": [
        "print(\"TRAINING\")\n",
        "regressionSummary(train_target, knnmodel.predict(train_predictors))\n",
        "print()\n",
        "print(\"VALIDATION\")\n",
        "regressionSummary(valid_target, knnmodel.predict(valid_predictors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp6ijUZZV9vm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeUSjZG9V9vm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EyHE2OxV9vn"
      },
      "source": [
        "### Now let us build a Decision Tree Regressor - for which we don't need scaled data. In fact we should not used scaled data since the decision Tree would lose its interpetability to the business. \n",
        "#### Note that car_df has the unscaled predcitors \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7Z2auTsV9vn"
      },
      "source": [
        "### \n",
        "train_predictors, valid_predictors, train_target, valid_target = train_test_split(car_df.drop(columns = {\"Price\"}), \n",
        "                                                    car_df[[\"Price\"]], test_size=0.3, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0EpQMbzV9vo"
      },
      "source": [
        "train_predictors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ-c8U1tV9vp"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfJ0RzGtV9vw"
      },
      "source": [
        "# Define the Regression Tree model and fit it to Training data \n",
        "regTree = DecisionTreeRegressor(max_depth= 3, min_samples_split = 20)\n",
        "regTree.fit(train_predictors,train_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oKwo8_dQV9vx"
      },
      "source": [
        "print(\"TRAINING\")\n",
        "regressionSummary(train_target, regTree.predict(train_predictors))\n",
        "print()\n",
        "print(\"VALIDATION\")\n",
        "regressionSummary(valid_target, regTree.predict(valid_predictors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4g30Bu0V9vy"
      },
      "source": [
        "#### In this case, Decision Trees seem to come up with a more accurate model ! And it does not seem to be overfitting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMx5HOCeV9vy"
      },
      "source": [
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz300f6fV9vz"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2FqT7XaoV9vz"
      },
      "source": [
        "plt.figure(figsize=(18,12))  # set plot size (denoted in inches)\n",
        "plot_tree(regTree, feature_names=list(train_predictors.columns),filled=True, fontsize=10)\n",
        "plt.show\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWFjHbHtV9v1"
      },
      "source": [
        "#### Now we apply Random Forests "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo-pN_hfV9v1"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLeP317jV9v2"
      },
      "source": [
        "rf_toyota= RandomForestRegressor(n_estimators=20, random_state=1)\n",
        "rf_toyota.fit(train_predictors,train_target)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGdmZozFV9v3"
      },
      "source": [
        "print(\"TRAINING\")\n",
        "regressionSummary(train_target, rf_toyota.predict(train_predictors))\n",
        "print()\n",
        "print(\"VALIDATION\")\n",
        "regressionSummary(valid_target, rf_toyota.predict(valid_predictors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf1o06QZV9v4"
      },
      "source": [
        "### Now we will apply Linear Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdrwcYH9V9v5"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "from dmba import regressionSummary\n",
        "%matplotlib inline "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbbtfWGAV9v5"
      },
      "source": [
        "# # Define a Linear Regression model and fit it to Training data\n",
        "\n",
        "linreg_toyota = LinearRegression()\n",
        "linreg_toyota.fit(train_predictors,train_target)   # this step finds the best beta parameters \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "5pzgCR8lV9v5"
      },
      "source": [
        "# we can print the best beta coefficients\n",
        "print('intercept or beta0 = ',linreg_toyota.intercept_[0])\n",
        "BetaMatrix = (pd.DataFrame({'Predictor': train_predictors.columns, 'Beta_coefficient': linreg_toyota.coef_[0] }))\n",
        "BetaMatrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_aZT0nuV9v6"
      },
      "source": [
        "#### This means that for THIS predictive model \n",
        " \n",
        " #### Predicted Price =\n",
        " \n",
        " #### The coefficients have interesting interpretations:\n",
        "\n",
        "#### If everything else remains the same: \n",
        "     1. The sale price of car decreases by  Euros for every additional month of Age \n",
        "     2. The sale price of car decreases by  Euros for every additional KM on the car.\n",
        "     3. Having Diesel as fuel type provides a increase in sale price of  euros over an identical car with CNG Fuel \n",
        "     4. Having Petrol as fuel type provides a increase in sale price of euros over an identical car with CNG Fuel "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZoHvvlfV9v6"
      },
      "source": [
        "valid_target[\"Predicted_Price\"] = linreg_toyota.predict(valid_predictors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CYaCvqFjV9v6"
      },
      "source": [
        "valid_target.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK3d9BwEV9v8"
      },
      "source": [
        "valid_target[\"Error_PricePrediction\"] = (valid_target.Predicted_Price - valid_target.Price) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMwuadXaV9v8"
      },
      "source": [
        "valid_target.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA7sv83kV9v9"
      },
      "source": [
        "sns.relplot(data=valid_target, x=\"Price\", y=\"Predicted_Price\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOQBqiOJV9v9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HjvuFxw5V9v9"
      },
      "source": [
        "sns.relplot(data=valid_target[(valid_target.Predicted_Price>= 0)], x=\"Price\", y=\"Predicted_Price\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwkzQaAjV9v9"
      },
      "source": [
        "valid_results.Predicted_Price.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6FilbLYV9v-"
      },
      "source": [
        "valid_predictors[(valid_target.Predicted_Price < 0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyOPXQ9vV9v-"
      },
      "source": [
        "#### Seems like a data entry error.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO7hIA2hV9v-"
      },
      "source": [
        "valid_predictors.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIuBZ0MeV9v_"
      },
      "source": [
        "#### Let us drop that row from the validation dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Fey-5m5AV9v_"
      },
      "source": [
        "valid_predictors = valid_predictors.drop(index = {80})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtYHZtm3V9v_"
      },
      "source": [
        "valid_target = valid_target.drop(index = {80}) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPaetmzgV9v_"
      },
      "source": [
        "valid_results = valid_results.drop(index = {80})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzwrpKgzV9v_"
      },
      "source": [
        "valid_predictors.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VGhOvqtV9wA"
      },
      "source": [
        "valid_target.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8T_WTCcV9wA"
      },
      "source": [
        "sns.relplot(data=valid_results, x=\"Price\", y=\"Predicted_Price\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH4l-_i1V9wA"
      },
      "source": [
        "print(\"TRAINING - Linear Regression\")\n",
        "regressionSummary(train_target,linreg_toyota.predict(train_predictors))\n",
        "print()\n",
        "print(\"VALIDATION -Linear Regression\")\n",
        "regressionSummary(valid_target[\"Price\"], regTree.predict(valid_predictors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URx3eXU-V9wA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTu-0ho_V9wB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMK7CaXUV9wB"
      },
      "source": [
        "####  Class Exercise:\n",
        "    1. Build a linear regression model using just two predictors Age and KM  ?\n",
        "    2. How good is this model ? \n",
        "    \n",
        "    Hint: In the above code every where you see train_predictors or valid_predictors, you have to replace it with train_predictors[\"Age\",\"KM] and valid_predictors[\"Age\", \"KM\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov-aMQpcV9wB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9alO1uaXV9wB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
